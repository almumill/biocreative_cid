{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf9521d-d841-4233-96f7-7910fd1abdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4e49593-1324-4c01-ba75-f17c3b501437",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path=\"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbb950d2-1c02-4802-82b5-11ffa50a031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes=[\"16\", \"32\", \"48\", \"64\"]\n",
    "learning_rates=[\"1e-05\", \"3e-05\", \"5e-05\"]\n",
    "weighted_loss=[\"weighted_loss\", \"unweighted_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4b9949ed-1114-4ce4-997f-873de6314066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3909/405354426.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  full_results = pd.concat([full_results, pd.DataFrame(row, index=[0])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "full_results = None\n",
    "full_results = pd.DataFrame(columns=[\"batch_size\", \"learning_rate\", \"loss_type\", \"iteration\", \"validation_loss\", \"f1\"])\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for learning_rate in learning_rates:\n",
    "        for loss in weighted_loss:\n",
    "            train_metrics_file = os.path.join(models_path, \"batch_size_\" + batch_size, \"lr_\" + learning_rate, loss, \"train_metrics.txt\")\n",
    "            lines = open(train_metrics_file).readlines()\n",
    "                \n",
    "            for idx, line in enumerate(lines):\n",
    "                iter, val_loss, f1 = line.rstrip().split(\"\\t\")\n",
    "                row = {\"batch_size\": batch_size, \"learning_rate\": learning_rate, \"loss_type\": loss, \"iteration\": str(idx), \"validation_loss\": val_loss, \"f1\": float(f1)}\n",
    "                full_results = pd.concat([full_results, pd.DataFrame(row, index=[0])], ignore_index=True)\n",
    "             \n",
    "            \n",
    "            #full_results = full_results.append(row, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dd92c67a-4ebb-4ebf-8b4f-5aa1fb93f9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>iteration</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>weighted_loss</td>\n",
       "      <td>0</td>\n",
       "      <td>2673.41246124357</td>\n",
       "      <td>0.462891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>weighted_loss</td>\n",
       "      <td>1</td>\n",
       "      <td>2433.83402332291</td>\n",
       "      <td>0.461467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>weighted_loss</td>\n",
       "      <td>2</td>\n",
       "      <td>2081.525285212323</td>\n",
       "      <td>0.477034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>weighted_loss</td>\n",
       "      <td>3</td>\n",
       "      <td>2091.1225312030874</td>\n",
       "      <td>0.485034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>weighted_loss</td>\n",
       "      <td>4</td>\n",
       "      <td>2752.6554140564986</td>\n",
       "      <td>0.473079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>64</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>unweighted_loss</td>\n",
       "      <td>5</td>\n",
       "      <td>2524.979742158437</td>\n",
       "      <td>0.444725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>64</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>unweighted_loss</td>\n",
       "      <td>6</td>\n",
       "      <td>2822.553178824368</td>\n",
       "      <td>0.441848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>64</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>unweighted_loss</td>\n",
       "      <td>7</td>\n",
       "      <td>3006.5621542709123</td>\n",
       "      <td>0.472892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>64</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>unweighted_loss</td>\n",
       "      <td>8</td>\n",
       "      <td>2732.305887785784</td>\n",
       "      <td>0.424942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>64</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>unweighted_loss</td>\n",
       "      <td>9</td>\n",
       "      <td>2794.017049532529</td>\n",
       "      <td>0.440587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    batch_size learning_rate        loss_type iteration     validation_loss  \\\n",
       "0           16         1e-05    weighted_loss         0    2673.41246124357   \n",
       "1           16         1e-05    weighted_loss         1    2433.83402332291   \n",
       "2           16         1e-05    weighted_loss         2   2081.525285212323   \n",
       "3           16         1e-05    weighted_loss         3  2091.1225312030874   \n",
       "4           16         1e-05    weighted_loss         4  2752.6554140564986   \n",
       "..         ...           ...              ...       ...                 ...   \n",
       "235         64         5e-05  unweighted_loss         5   2524.979742158437   \n",
       "236         64         5e-05  unweighted_loss         6   2822.553178824368   \n",
       "237         64         5e-05  unweighted_loss         7  3006.5621542709123   \n",
       "238         64         5e-05  unweighted_loss         8   2732.305887785784   \n",
       "239         64         5e-05  unweighted_loss         9   2794.017049532529   \n",
       "\n",
       "           f1  \n",
       "0    0.462891  \n",
       "1    0.461467  \n",
       "2    0.477034  \n",
       "3    0.485034  \n",
       "4    0.473079  \n",
       "..        ...  \n",
       "235  0.444725  \n",
       "236  0.441848  \n",
       "237  0.472892  \n",
       "238  0.424942  \n",
       "239  0.440587  \n",
       "\n",
       "[240 rows x 6 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results.f1 = full_results.f1.astype(float)\n",
    "full_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f6a2c07a-9c73-437a-86a2-ea27e2c24df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>iteration</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>16</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>unweighted_loss</td>\n",
       "      <td>0</td>\n",
       "      <td>1984.4557107053697</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>32</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>unweighted_loss</td>\n",
       "      <td>0</td>\n",
       "      <td>1880.276549771428</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>32</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>unweighted_loss</td>\n",
       "      <td>0</td>\n",
       "      <td>1853.7790362276137</td>\n",
       "      <td>0.048469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>48</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>unweighted_loss</td>\n",
       "      <td>0</td>\n",
       "      <td>1811.441890694201</td>\n",
       "      <td>0.110159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>16</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>unweighted_loss</td>\n",
       "      <td>0</td>\n",
       "      <td>1839.4963525496423</td>\n",
       "      <td>0.119804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>64</td>\n",
       "      <td>5e-05</td>\n",
       "      <td>weighted_loss</td>\n",
       "      <td>2</td>\n",
       "      <td>1942.0625212877057</td>\n",
       "      <td>0.510737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>64</td>\n",
       "      <td>3e-05</td>\n",
       "      <td>weighted_loss</td>\n",
       "      <td>9</td>\n",
       "      <td>2899.205683891909</td>\n",
       "      <td>0.512244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>32</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>weighted_loss</td>\n",
       "      <td>9</td>\n",
       "      <td>2711.394499914837</td>\n",
       "      <td>0.512563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>32</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>weighted_loss</td>\n",
       "      <td>8</td>\n",
       "      <td>2550.464858230436</td>\n",
       "      <td>0.520482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>32</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>weighted_loss</td>\n",
       "      <td>7</td>\n",
       "      <td>2316.411303155357</td>\n",
       "      <td>0.526376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    batch_size learning_rate        loss_type iteration     validation_loss  \\\n",
       "50          16         5e-05  unweighted_loss         0  1984.4557107053697   \n",
       "110         32         5e-05  unweighted_loss         0   1880.276549771428   \n",
       "90          32         3e-05  unweighted_loss         0  1853.7790362276137   \n",
       "170         48         5e-05  unweighted_loss         0   1811.441890694201   \n",
       "30          16         3e-05  unweighted_loss         0  1839.4963525496423   \n",
       "..         ...           ...              ...       ...                 ...   \n",
       "222         64         5e-05    weighted_loss         2  1942.0625212877057   \n",
       "209         64         3e-05    weighted_loss         9   2899.205683891909   \n",
       "69          32         1e-05    weighted_loss         9   2711.394499914837   \n",
       "68          32         1e-05    weighted_loss         8   2550.464858230436   \n",
       "67          32         1e-05    weighted_loss         7   2316.411303155357   \n",
       "\n",
       "           f1  \n",
       "50   0.000000  \n",
       "110  0.000000  \n",
       "90   0.048469  \n",
       "170  0.110159  \n",
       "30   0.119804  \n",
       "..        ...  \n",
       "222  0.510737  \n",
       "209  0.512244  \n",
       "69   0.512563  \n",
       "68   0.520482  \n",
       "67   0.526376  \n",
       "\n",
       "[240 rows x 6 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results.sort_values(by=[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c942f2f7-f1af-414d-a3f9-d0a3d7617ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
